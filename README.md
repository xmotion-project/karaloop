<p align="center">
	<img src="https://github.com/xmotion-project/xMotion/blob/main/src/Logo.jpg" width="50%" />
</p>

Can you imagine people interacting with phones, tablets, computers and other devices without hands? 

The **xMotion Project** is an initiative to advance the development of accessible wearable hands-free interfaces that will allow anyone to interact with any device, *without hands*, simply by performing movements of the face :relaxed:

The primary goal of xMotion is to enable ubiquitous human-device interaction to all - regardles of physical abilities and environmental constrains.   

(include video)

## Contents of this repository

This repository contains a collection of wearable orofacial hands-free 
interface designs developed  .
Originally, it also contained the AVR and SAM Arduino core and libraries
(i.e.  the code that is compiled as part of a sketch and runs on the
actual Arduino device), but those have been moved into their own
repositories.  They are still automatically downloaded as part of the
build process and included in built releases, though.

## Details on each xMotion design are on

[Our wiki](https://www.arduino.cc/)

## All xMotion interfaces use

[Arduino IDE](https://www.arduino.cc/en/software),
[Adafruit Feather nRF52 Bluefruit](https://learn.adafruit.com/bluefruit-nrf52-feather-learning-guide?view=all), and
[Arduino BSP for Adafruit Bluefruit nRF52 series](https://github.com/adafruit/Adafruit_nRF52_Arduino)

## Credits

xMotion is sponsored by Fondation Privée des HUG and Wyss Center through grants awarded to Ferran Galán at University of Geneva.
The xMotion team is composed of Ahmad Jafaar, Quentin Praz, Spiros Schoinas and Philippe Passeraub from HEPIA, and Ferran Galán from University of Geneva.

## Repository status

All contents is private and confidential until decided otherwise. 
